{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Ic0rjrHwV5"
      },
      "source": [
        "# **Model Training:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eNngGJAKqfbF"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc, precision_recall_fscore_support, confusion_matrix\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from scipy.stats import mode\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as preprocess_input_inception\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as preprocess_input_resnet\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input as preprocess_input_densenet\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsqHoU5sqgjX",
        "outputId": "014829d3-693e-4dc6-cf49-5b26ca22c797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lpA8WoE9Hncj"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/drive/MyDrive/Data 298B Project Data/Rice Image Datasets - with Location and Time/Rice Leaf Diseases - Taiwan Filtered\"\n",
        "\n",
        "#df = pd.read_csv(f\"{base_dir}/main_df_rice.csv\")\n",
        "df = pd.read_csv(f\"{base_dir}/image_metadata_taiwan_filtered_location.csv\")\n",
        "train_df = pd.read_csv(f\"{base_dir}/train_df_with_augmentation_rice.csv\")\n",
        "val_df = pd.read_csv(f\"{base_dir}/val_df_rice.csv\")\n",
        "test_df = pd.read_csv(f\"{base_dir}/test_df_rice.csv\")\n",
        "\n",
        "train_image_dir = f'{base_dir}/Train_Dataset_with_Augmentation_Rice'\n",
        "val_image_dir = f'{base_dir}/Validation_Dataset_Rice'\n",
        "test_image_dir = f'{base_dir}/Test_Dataset_Rice'\n",
        "\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding the Class Variable\n",
        "label_encoder = LabelEncoder()\n",
        "labels = df['Class'].unique()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Saving the label encodings to a file\n",
        "\n",
        "joblib.dump(label_encoder, f\"{base_dir}/label_encoder.joblib\")"
      ],
      "metadata": {
        "id": "0mkVj8XspnVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the label encodings from the previously made joblib file\n",
        "\n",
        "label_encoder = joblib.load(f'{base_dir}/label_encoder.joblib')"
      ],
      "metadata": {
        "id": "mgbJ57e_psoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX2AjXoEp36y"
      },
      "source": [
        "# **VGG19 Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwsM7kYVHz1u"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the images to meet the requirements of the pertinent pre-trained model\n",
        "def preprocess_image(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True) # Resizing to 224x224 for VGG19\n",
        "  img = preprocess_input_vgg(img)  # Applying the preprocess function for VGG19\n",
        "  return img, label\n",
        "\n",
        "# Function to prepare the train, validation and test datasets to be compatible with TensorFlow\n",
        "def prepare_dataset(df, image_dir, preprocessing_function, batch_size=32, cache=True, shuffle=False):\n",
        "    image_paths = df['Id'].apply(lambda x: f\"{image_dir}/{x}\").values\n",
        "    labels = label_encoder.transform(df['Class'].values)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    dataset = dataset.map(preprocessing_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgN_tTQNIH-C"
      },
      "outputs": [],
      "source": [
        "# Preparing the train, validation and test datasets, with shuffling for the train dataset\n",
        "train_dataset = prepare_dataset(train_df, train_image_dir, preprocess_image, batch_size=batch_size, cache=True, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_df, val_image_dir, preprocess_image, batch_size=batch_size, cache=True)\n",
        "test_dataset = prepare_dataset(test_df, test_image_dir, preprocess_image, batch_size=batch_size, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6reMO81pZxaz",
        "outputId": "d57140bc-4f57-4d11-f31b-83afba41d7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 7.3119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 91.20%, Test loss: 0.7600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 8.80%, Test loss: 1.0998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 88.00%, Test loss: 8.5694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 90.40%, Test loss: 1.6018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 8.80%, Test loss: 1.1011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 88.80%, Test loss: 4.6474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 87.20%, Test loss: 1.8419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 36.80%, Test loss: 1.0999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 91.20%, Test loss: 0.2148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 87.20%, Test loss: 0.3974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 36.80%, Test loss: 1.1125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 88.80%, Test loss: 0.2415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 84.80%, Test loss: 0.3521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 65.60%, Test loss: 0.7335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 90.40%, Test loss: 0.2959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 84.00%, Test loss: 0.4313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 44.80%, Test loss: 0.9595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 91.20%, Test loss: 3.9057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 0.7513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 54.40%, Test loss: 1.0622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 91.20%, Test loss: 1.8572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 2.0755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 54.40%, Test loss: 1.0984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 85.60%, Test loss: 7.4087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 3.2364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 54.40%, Test loss: 1.0960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 0.2623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 82.40%, Test loss: 0.3948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 70.40%, Test loss: 0.7928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 88.80%, Test loss: 0.3014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 82.40%, Test loss: 0.3702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 62.40%, Test loss: 1.0573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.60%, Test loss: 0.2909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 84.00%, Test loss: 0.3388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 68.00%, Test loss: 0.7355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f757cffcc1b1>:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        }
      ],
      "source": [
        "# Defining the parameter grid with various model combinations\n",
        "neuron_options = [2048, 4096]\n",
        "activation_options = ['relu', 'tanh']\n",
        "dropout_options = [0, 0.3, 0.5]\n",
        "# Loading the base VGG19 model to determine the total number of layers\n",
        "temp_model = VGG19(weights='imagenet', include_top=False)\n",
        "total_layers = len(temp_model.layers)\n",
        "frozen_layers_options = [total_layers, total_layers - 2, total_layers - 5]  # Experimenting with the number of frozen layers for further fine-tuning\n",
        "\n",
        "# Initializing a DataFrame to store the results of each model combination\n",
        "results_df = pd.DataFrame(columns=['Neurons', 'Activation', 'Dropout', 'Frozen Layers', 'Test Accuracy', 'Test Loss'])\n",
        "\n",
        "# Variables to keep track of the best model's accuracy and details\n",
        "best_accuracy = 0\n",
        "best_model_details = {}\n",
        "\n",
        "for neurons in neuron_options:\n",
        "    for activation in activation_options:\n",
        "        for dropout_rate in dropout_options:\n",
        "            for frozen_layers in frozen_layers_options:\n",
        "\n",
        "                # Loading the base VGG19 model\n",
        "                base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "                # Freezing the layers for further fine-tuning\n",
        "                for layer in base_model.layers[:frozen_layers]:\n",
        "                    layer.trainable = False\n",
        "\n",
        "                # Adding custom layers\n",
        "                x = base_model.output\n",
        "                x = Flatten()(x)\n",
        "                x = Dense(neurons, activation=activation)(x)\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "                predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "                # Complete model\n",
        "                model = Model(inputs=base_model.input, outputs=predictions)\n",
        "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                # Fitting the model\n",
        "                history = model.fit(\n",
        "                    train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=25,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)],\n",
        "                    verbose = 0\n",
        "                )\n",
        "\n",
        "                # Evaluating the model on the test set\n",
        "                test_loss, test_accuracy = model.evaluate(test_dataset, verbose = 0)\n",
        "                print(f\"Test accuracy: {test_accuracy * 100:.2f}%, Test loss: {test_loss:.4f}\")\n",
        "\n",
        "                # Updating the results DataFrame\n",
        "                results_df = results_df.append({\n",
        "                    'Neurons': neurons,\n",
        "                    'Activation': activation,\n",
        "                    'Dropout': dropout_rate,\n",
        "                    'Frozen Layers': frozen_layers,\n",
        "                    'Test Accuracy': test_accuracy,\n",
        "                    'Test Loss': test_loss\n",
        "                }, ignore_index=True)\n",
        "\n",
        "                # Saving the best model\n",
        "                if test_accuracy > best_accuracy:\n",
        "                    best_accuracy = test_accuracy\n",
        "                    best_model_details = {\n",
        "                        'Neurons': neurons,\n",
        "                        'Activation': activation,\n",
        "                        'Dropout': dropout_rate,\n",
        "                        'Frozen Layers': frozen_layers,\n",
        "                        'Test Set Accuracy': f\"{test_accuracy * 100:.2f}%\"\n",
        "                    }\n",
        "                    model.save(f'{base_dir}/Best_VGG19_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bVwS9p_aljc",
        "outputId": "5985b14a-5ffb-4fb6-ebaf-6aa0e3beba8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Neurons Activation Dropout Frozen Layers  Test Accuracy  Test Loss\n",
            "0     2048       relu       0            22          0.896   7.311944\n",
            "1     2048       relu       0            20          0.912   0.760017\n",
            "2     2048       relu       0            17          0.088   1.099824\n",
            "3     2048       relu     0.3            22          0.880   8.569437\n",
            "4     2048       relu     0.3            20          0.904   1.601842\n",
            "5     2048       relu     0.3            17          0.088   1.101093\n",
            "6     2048       relu     0.5            22          0.888   4.647356\n",
            "7     2048       relu     0.5            20          0.872   1.841907\n",
            "8     2048       relu     0.5            17          0.368   1.099905\n",
            "9     2048       tanh       0            22          0.912   0.214835\n",
            "10    2048       tanh       0            20          0.872   0.397380\n",
            "11    2048       tanh       0            17          0.368   1.112538\n",
            "12    2048       tanh     0.3            22          0.888   0.241474\n",
            "13    2048       tanh     0.3            20          0.848   0.352143\n",
            "14    2048       tanh     0.3            17          0.656   0.733498\n",
            "15    2048       tanh     0.5            22          0.904   0.295930\n",
            "16    2048       tanh     0.5            20          0.840   0.431299\n",
            "17    2048       tanh     0.5            17          0.448   0.959481\n",
            "18    4096       relu       0            22          0.912   3.905750\n",
            "19    4096       relu       0            20          0.896   0.751336\n",
            "20    4096       relu       0            17          0.544   1.062249\n",
            "21    4096       relu     0.3            22          0.912   1.857189\n",
            "22    4096       relu     0.3            20          0.896   2.075461\n",
            "23    4096       relu     0.3            17          0.544   1.098373\n",
            "24    4096       relu     0.5            22          0.856   7.408736\n",
            "25    4096       relu     0.5            20          0.896   3.236386\n",
            "26    4096       relu     0.5            17          0.544   1.096019\n",
            "27    4096       tanh       0            22          0.896   0.262257\n",
            "28    4096       tanh       0            20          0.824   0.394759\n",
            "29    4096       tanh       0            17          0.704   0.792827\n",
            "30    4096       tanh     0.3            22          0.888   0.301399\n",
            "31    4096       tanh     0.3            20          0.824   0.370247\n",
            "32    4096       tanh     0.3            17          0.624   1.057344\n",
            "33    4096       tanh     0.5            22          0.896   0.290857\n",
            "34    4096       tanh     0.5            20          0.840   0.338838\n",
            "35    4096       tanh     0.5            17          0.680   0.735464\n"
          ]
        }
      ],
      "source": [
        "# Displaying all results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJY2d39gLaH",
        "outputId": "49628a0e-1509-418a-b2d6-a46590557ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model details: {'Neurons': 2048, 'Activation': 'relu', 'Dropout': 0, 'Frozen Layers': 20, 'Test Set Accuracy': '91.20%'}\n"
          ]
        }
      ],
      "source": [
        "# Displaying the best model's details\n",
        "print(\"Best model details:\", best_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPYzzLgDrBib"
      },
      "source": [
        "# **InceptionV3 Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZbNCmrMhrDn0"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the images to meet the requirements of the pertinent pre-trained model\n",
        "def preprocess_image(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 299, 299, antialias=True) # Resizing to 299x299 for InceptionV3\n",
        "  img = preprocess_input_inception(img)  # Applying the preprocess function for InceptionV3\n",
        "  return img, label\n",
        "\n",
        "# Label Encoding the Class Variable\n",
        "label_encoder = LabelEncoder()\n",
        "labels = df['Class'].unique()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Function to prepare the train, validation and test datasets to be compatible with TensorFlow\n",
        "def prepare_dataset(df, image_dir, preprocessing_function, batch_size=32, cache=True, shuffle=False):\n",
        "    image_paths = df['Id'].apply(lambda x: f\"{image_dir}/{x}\").values\n",
        "    labels = label_encoder.transform(df['Class'].values)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    dataset = dataset.map(preprocessing_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y_asDMr5res-"
      },
      "outputs": [],
      "source": [
        "# Preparing the train, validation and test datasets, with shuffling for the train dataset\n",
        "train_dataset = prepare_dataset(train_df, train_image_dir, preprocess_image, batch_size=batch_size, cache=True, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_df, val_image_dir, preprocess_image, batch_size=batch_size, cache=True)\n",
        "test_dataset = prepare_dataset(test_df, test_image_dir, preprocess_image, batch_size=batch_size, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EGL6m-h2jnEz"
      },
      "outputs": [],
      "source": [
        "# Clearing unnecessary memory usage before training the model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dliLelwggsbr",
        "outputId": "6e74b190-867b-455e-9a29-548b220d4273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Test accuracy: 92.00%, Test loss: 0.8233\n",
            "Test accuracy: 95.20%, Test loss: 0.2030\n",
            "Test accuracy: 91.20%, Test loss: 1.4841\n",
            "Test accuracy: 92.00%, Test loss: 0.1771\n",
            "Test accuracy: 92.00%, Test loss: 0.4073\n",
            "Test accuracy: 89.60%, Test loss: 0.3049\n",
            "Test accuracy: 88.80%, Test loss: 0.4312\n",
            "Test accuracy: 88.80%, Test loss: 0.2720\n",
            "Test accuracy: 86.40%, Test loss: 0.4835\n",
            "Test accuracy: 92.00%, Test loss: 0.8425\n",
            "Test accuracy: 90.40%, Test loss: 2.0492\n",
            "Test accuracy: 91.20%, Test loss: 1.4574\n",
            "Test accuracy: 93.60%, Test loss: 0.3910\n",
            "Test accuracy: 92.00%, Test loss: 1.1069\n",
            "Test accuracy: 89.60%, Test loss: 1.6758\n",
            "Test accuracy: 92.80%, Test loss: 0.2129\n",
            "Test accuracy: 91.20%, Test loss: 0.4318\n",
            "Test accuracy: 89.60%, Test loss: 0.9262\n"
          ]
        }
      ],
      "source": [
        "# Defining the parameter grid with various model combinations\n",
        "neuron_options = [256, 512]\n",
        "activation_options = ['relu']\n",
        "dropout_options = [0, 0.3, 0.5]\n",
        "# Loading the base InceptionV3 model to determine the total number of layers\n",
        "temp_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "total_layers = len(temp_model.layers)\n",
        "frozen_layers_options = [total_layers, total_layers - 2, total_layers - 5]  # Experimenting with the number of frozen layers for further fine-tuning\n",
        "\n",
        "# Initializing a DataFrame to store the results of each model combination\n",
        "results_df = pd.DataFrame(columns=['Neurons', 'Activation', 'Dropout', 'Frozen Layers', 'Test Accuracy', 'Test Loss'])\n",
        "\n",
        "# Variables to keep track of the best model's accuracy and details\n",
        "best_accuracy = 0\n",
        "best_model_details = {}\n",
        "\n",
        "for neurons in neuron_options:\n",
        "    for activation in activation_options:\n",
        "        for dropout_rate in dropout_options:\n",
        "            for frozen_layers in frozen_layers_options:\n",
        "\n",
        "                # Loading the base InceptionV3 model\n",
        "                base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "                # Freezing the layers for further fine-tuning\n",
        "                for layer in base_model.layers[:frozen_layers]:\n",
        "                    layer.trainable = False\n",
        "\n",
        "                # Adding custom layers\n",
        "                x = base_model.output\n",
        "                x = Flatten()(x)\n",
        "                x = Dense(neurons, activation=activation)(x)\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "                predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "                # Complete model\n",
        "                model = Model(inputs=base_model.input, outputs=predictions)\n",
        "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                # Fitting the model\n",
        "                history = model.fit(\n",
        "                    train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=25,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)],\n",
        "                    verbose = 0\n",
        "                )\n",
        "\n",
        "                # Evaluating the model on the test set\n",
        "                test_loss, test_accuracy = model.evaluate(test_dataset, verbose = 0)\n",
        "                print(f\"Test accuracy: {test_accuracy * 100:.2f}%, Test loss: {test_loss:.4f}\")\n",
        "\n",
        "                # Updating the results DataFrame\n",
        "                results_df = results_df.append({\n",
        "                    'Neurons': neurons,\n",
        "                    'Activation': activation,\n",
        "                    'Dropout': dropout_rate,\n",
        "                    'Frozen Layers': frozen_layers,\n",
        "                    'Test Accuracy': test_accuracy,\n",
        "                    'Test Loss': test_loss\n",
        "                }, ignore_index=True)\n",
        "\n",
        "                # Saving the best model\n",
        "                if test_accuracy > best_accuracy:\n",
        "                    best_accuracy = test_accuracy\n",
        "                    best_model_details = {\n",
        "                        'Neurons': neurons,\n",
        "                        'Activation': activation,\n",
        "                        'Dropout': dropout_rate,\n",
        "                        'Frozen Layers': frozen_layers,\n",
        "                        'Test Set Accuracy': f\"{test_accuracy * 100:.2f}%\"\n",
        "                    }\n",
        "                    model.save(f'{base_dir}/Best_InceptionV3_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bjCVjTkmk2KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca09348-7363-408c-98d1-914d72fbf69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Neurons Activation Dropout Frozen Layers  Test Accuracy  Test Loss\n",
            "0      256       relu       0           311          0.920   0.823283\n",
            "1      256       relu       0           309          0.952   0.203033\n",
            "2      256       relu       0           306          0.912   1.484068\n",
            "3      256       relu     0.3           311          0.920   0.177078\n",
            "4      256       relu     0.3           309          0.920   0.407330\n",
            "5      256       relu     0.3           306          0.896   0.304904\n",
            "6      256       relu     0.5           311          0.888   0.431158\n",
            "7      256       relu     0.5           309          0.888   0.272027\n",
            "8      256       relu     0.5           306          0.864   0.483468\n",
            "9      512       relu       0           311          0.920   0.842484\n",
            "10     512       relu       0           309          0.904   2.049221\n",
            "11     512       relu       0           306          0.912   1.457391\n",
            "12     512       relu     0.3           311          0.936   0.391002\n",
            "13     512       relu     0.3           309          0.920   1.106900\n",
            "14     512       relu     0.3           306          0.896   1.675820\n",
            "15     512       relu     0.5           311          0.928   0.212894\n",
            "16     512       relu     0.5           309          0.912   0.431773\n",
            "17     512       relu     0.5           306          0.896   0.926229\n"
          ]
        }
      ],
      "source": [
        "# Displaying all results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NuQu_tS_k2-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2dcc37-77f1-4d7c-fda5-8212065f3285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model details: {'Neurons': 256, 'Activation': 'relu', 'Dropout': 0, 'Frozen Layers': 309, 'Test Set Accuracy': '95.20%'}\n"
          ]
        }
      ],
      "source": [
        "# Displaying the best model's details\n",
        "print(\"Best model details:\", best_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vza_bobWsHsw"
      },
      "source": [
        "# **ResNet50 Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WdxoE34QsG30"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the images to meet the requirements of the pertinent pre-trained model\n",
        "def preprocess_image(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True) # Resizing to 224x224 for ResNet50\n",
        "  img = preprocess_input_resnet(img)  # Applying the preprocess function for ResNet50\n",
        "  return img, label\n",
        "\n",
        "# Label Encoding the Class Variable\n",
        "label_encoder = LabelEncoder()\n",
        "labels = df['Class'].unique()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Function to prepare the train, validation and test datasets to be compatible with TensorFlow\n",
        "def prepare_dataset(df, image_dir, preprocessing_function, batch_size=32, cache=True, shuffle=False):\n",
        "    image_paths = df['Id'].apply(lambda x: f\"{image_dir}/{x}\").values\n",
        "    labels = label_encoder.transform(df['Class'].values)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    dataset = dataset.map(preprocessing_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a7T9NwIHsmV3"
      },
      "outputs": [],
      "source": [
        "# Preparing the train, validation and test datasets, with shuffling for the train dataset\n",
        "train_dataset = prepare_dataset(train_df, train_image_dir, preprocess_image, batch_size=batch_size, cache=True, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_df, val_image_dir, preprocess_image, batch_size=batch_size, cache=True)\n",
        "test_dataset = prepare_dataset(test_df, test_image_dir, preprocess_image, batch_size=batch_size, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clearing unnecessary memory usage before training the model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "iFCnVfzGX3Pg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QOKUuiD2lo9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156753c7-40d1-45bf-a79b-45c52b5929dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 96.00%, Test loss: 0.1683\n",
            "Test accuracy: 96.00%, Test loss: 0.1682\n",
            "Test accuracy: 94.40%, Test loss: 0.3475\n",
            "Test accuracy: 97.60%, Test loss: 0.1171\n",
            "Test accuracy: 96.00%, Test loss: 0.4765\n",
            "Test accuracy: 93.60%, Test loss: 0.4985\n",
            "Test accuracy: 96.00%, Test loss: 0.3298\n",
            "Test accuracy: 92.00%, Test loss: 0.4952\n",
            "Test accuracy: 95.20%, Test loss: 0.3764\n",
            "Test accuracy: 94.40%, Test loss: 0.7463\n",
            "Test accuracy: 96.00%, Test loss: 0.2710\n",
            "Test accuracy: 94.40%, Test loss: 0.4725\n",
            "Test accuracy: 93.60%, Test loss: 2.2460\n",
            "Test accuracy: 95.20%, Test loss: 0.9702\n",
            "Test accuracy: 96.00%, Test loss: 0.8577\n",
            "Test accuracy: 91.20%, Test loss: 1.4642\n",
            "Test accuracy: 96.00%, Test loss: 0.4452\n",
            "Test accuracy: 93.60%, Test loss: 0.6054\n"
          ]
        }
      ],
      "source": [
        "# Defining the parameter grid with various model combinations\n",
        "neuron_options = [256, 512]\n",
        "activation_options = ['relu']\n",
        "dropout_options = [0, 0.3, 0.5]\n",
        "# Loading the base ResNet50 model to determine the total number of layers\n",
        "temp_model = ResNet50(weights='imagenet', include_top=False)\n",
        "total_layers = len(temp_model.layers)\n",
        "frozen_layers_options = [total_layers, total_layers - 2, total_layers - 5]  # Experimenting with the number of frozen layers for further fine-tuning\n",
        "\n",
        "# Initializing a DataFrame to store the results of each model combination\n",
        "results_df = pd.DataFrame(columns=['Neurons', 'Activation', 'Dropout', 'Frozen Layers', 'Test Accuracy', 'Test Loss'])\n",
        "\n",
        "# Variables to keep track of the best model's accuracy and details\n",
        "best_accuracy = 0\n",
        "best_model_details = {}\n",
        "\n",
        "for neurons in neuron_options:\n",
        "    for activation in activation_options:\n",
        "        for dropout_rate in dropout_options:\n",
        "            for frozen_layers in frozen_layers_options:\n",
        "\n",
        "                # Loading the base ResNet50 model\n",
        "                base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "                # Freezing the layers for further fine-tuning\n",
        "                for layer in base_model.layers[:frozen_layers]:\n",
        "                    layer.trainable = False\n",
        "\n",
        "                # Adding custom layers\n",
        "                x = base_model.output\n",
        "                x = Flatten()(x)\n",
        "                x = Dense(neurons, activation=activation)(x)\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "                predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "                # Complete model\n",
        "                model = Model(inputs=base_model.input, outputs=predictions)\n",
        "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                # Fitting the model\n",
        "                history = model.fit(\n",
        "                    train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=25,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)],\n",
        "                    verbose = 0\n",
        "                )\n",
        "\n",
        "                # Evaluating the model on the test set\n",
        "                test_loss, test_accuracy = model.evaluate(test_dataset, verbose = 0)\n",
        "                print(f\"Test accuracy: {test_accuracy * 100:.2f}%, Test loss: {test_loss:.4f}\")\n",
        "\n",
        "                # Updating the results DataFrame\n",
        "                results_df = results_df.append({\n",
        "                    'Neurons': neurons,\n",
        "                    'Activation': activation,\n",
        "                    'Dropout': dropout_rate,\n",
        "                    'Frozen Layers': frozen_layers,\n",
        "                    'Test Accuracy': test_accuracy,\n",
        "                    'Test Loss': test_loss\n",
        "                }, ignore_index=True)\n",
        "\n",
        "                # Saving the best model\n",
        "                if test_accuracy > best_accuracy:\n",
        "                    best_accuracy = test_accuracy\n",
        "                    best_model_details = {\n",
        "                        'Neurons': neurons,\n",
        "                        'Activation': activation,\n",
        "                        'Dropout': dropout_rate,\n",
        "                        'Frozen Layers': frozen_layers,\n",
        "                        'Test Set Accuracy': f\"{test_accuracy * 100:.2f}%\"\n",
        "                    }\n",
        "                    model.save(f'{base_dir}/Best_ResNet50_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XL7maRbVl5p0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d223160-01f1-4587-8ed4-4614c844a3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Neurons Activation Dropout Frozen Layers  Test Accuracy  Test Loss\n",
            "0      256       relu       0           175          0.960   0.168293\n",
            "1      256       relu       0           173          0.960   0.168230\n",
            "2      256       relu       0           170          0.944   0.347500\n",
            "3      256       relu     0.3           175          0.976   0.117062\n",
            "4      256       relu     0.3           173          0.960   0.476467\n",
            "5      256       relu     0.3           170          0.936   0.498494\n",
            "6      256       relu     0.5           175          0.960   0.329796\n",
            "7      256       relu     0.5           173          0.920   0.495200\n",
            "8      256       relu     0.5           170          0.952   0.376444\n",
            "9      512       relu       0           175          0.944   0.746336\n",
            "10     512       relu       0           173          0.960   0.271041\n",
            "11     512       relu       0           170          0.944   0.472504\n",
            "12     512       relu     0.3           175          0.936   2.245982\n",
            "13     512       relu     0.3           173          0.952   0.970200\n",
            "14     512       relu     0.3           170          0.960   0.857723\n",
            "15     512       relu     0.5           175          0.912   1.464189\n",
            "16     512       relu     0.5           173          0.960   0.445240\n",
            "17     512       relu     0.5           170          0.936   0.605361\n"
          ]
        }
      ],
      "source": [
        "# Displaying all results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "81--SNN9l_Sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f56593-55c8-4e5e-8df9-b3d9c25e545d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model details: {'Neurons': 256, 'Activation': 'relu', 'Dropout': 0.3, 'Frozen Layers': 175, 'Test Set Accuracy': '97.60%'}\n"
          ]
        }
      ],
      "source": [
        "# Displaying the best model's details\n",
        "print(\"Best model details:\", best_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfycnw7ktCyt"
      },
      "source": [
        "# **DenseNet121 Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wi0v9uuztFE0"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the images to meet the requirements of the pertinent pre-trained model\n",
        "def preprocess_image(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True) # Resizing to 224x224 for DenseNet121\n",
        "  img = preprocess_input_densenet(img)  # Applying the preprocess function for DenseNet121\n",
        "  return img, label\n",
        "\n",
        "# Label Encoding the Class Variable\n",
        "label_encoder = LabelEncoder()\n",
        "labels = df['Class'].unique()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Function to prepare the train, validation and test datasets to be compatible with TensorFlow\n",
        "def prepare_dataset(df, image_dir, preprocessing_function, batch_size=32, cache=True, shuffle=False):\n",
        "    image_paths = df['Id'].apply(lambda x: f\"{image_dir}/{x}\").values\n",
        "    labels = label_encoder.transform(df['Class'].values)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    dataset = dataset.map(preprocessing_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ejwzwcPdtPvX"
      },
      "outputs": [],
      "source": [
        "# Preparing the train, validation and test datasets, with shuffling for the train dataset\n",
        "train_dataset = prepare_dataset(train_df, train_image_dir, preprocess_image, batch_size=batch_size, cache=True, shuffle=True)\n",
        "val_dataset = prepare_dataset(val_df, val_image_dir, preprocess_image, batch_size=batch_size, cache=True)\n",
        "test_dataset = prepare_dataset(test_df, test_image_dir, preprocess_image, batch_size=batch_size, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clearing unnecessary memory usage before training the model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "wY0UwzVfX5HQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GWv3GtCAmf2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356c102c-ad82-4e16-827c-d5685291801e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "Test accuracy: 96.80%, Test loss: 0.1207\n",
            "Test accuracy: 94.40%, Test loss: 0.2201\n",
            "Test accuracy: 95.20%, Test loss: 0.4653\n",
            "Test accuracy: 94.40%, Test loss: 0.1393\n",
            "Test accuracy: 95.20%, Test loss: 0.1335\n",
            "Test accuracy: 93.60%, Test loss: 0.2537\n",
            "Test accuracy: 92.00%, Test loss: 0.1645\n",
            "Test accuracy: 90.40%, Test loss: 0.1723\n",
            "Test accuracy: 93.60%, Test loss: 0.1620\n",
            "Test accuracy: 95.20%, Test loss: 0.2859\n",
            "Test accuracy: 96.80%, Test loss: 0.1456\n",
            "Test accuracy: 91.20%, Test loss: 0.3687\n",
            "Test accuracy: 96.00%, Test loss: 0.1015\n",
            "Test accuracy: 96.80%, Test loss: 0.1684\n",
            "Test accuracy: 92.00%, Test loss: 0.1748\n",
            "Test accuracy: 91.20%, Test loss: 0.2575\n",
            "Test accuracy: 91.20%, Test loss: 0.1886\n",
            "Test accuracy: 92.80%, Test loss: 0.2084\n"
          ]
        }
      ],
      "source": [
        "# Defining the parameter grid with various model combinations\n",
        "neuron_options = [256, 512]\n",
        "activation_options = ['relu']\n",
        "dropout_options = [0, 0.3, 0.5]\n",
        "# Loading the base DenseNet121 model to determine the total number of layers\n",
        "temp_model = DenseNet121(weights='imagenet', include_top=False)\n",
        "total_layers = len(temp_model.layers)\n",
        "frozen_layers_options = [total_layers, total_layers - 2, total_layers - 5]  # Experimenting with the number of frozen layers for further fine-tuning\n",
        "\n",
        "# Initializing a DataFrame to store the results of each model combination\n",
        "results_df = pd.DataFrame(columns=['Neurons', 'Activation', 'Dropout', 'Frozen Layers', 'Test Accuracy', 'Test Loss'])\n",
        "\n",
        "# Variables to keep track of the best model's accuracy and details\n",
        "best_accuracy = 0\n",
        "best_model_details = {}\n",
        "\n",
        "for neurons in neuron_options:\n",
        "    for activation in activation_options:\n",
        "        for dropout_rate in dropout_options:\n",
        "            for frozen_layers in frozen_layers_options:\n",
        "\n",
        "                # Loading the base DenseNet121 model\n",
        "                base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "                # Freezing the layers for further fine-tuning\n",
        "                for layer in base_model.layers[:frozen_layers]:\n",
        "                    layer.trainable = False\n",
        "\n",
        "                # Adding custom layers\n",
        "                x = base_model.output\n",
        "                x = Flatten()(x)\n",
        "                x = Dense(neurons, activation=activation)(x)\n",
        "                x = Dropout(dropout_rate)(x)\n",
        "                predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "                # Complete model\n",
        "                model = Model(inputs=base_model.input, outputs=predictions)\n",
        "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                # Fitting the model\n",
        "                history = model.fit(\n",
        "                    train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=25,\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)],\n",
        "                    verbose = 0\n",
        "                )\n",
        "\n",
        "                # Evaluating the model on the test set\n",
        "                test_loss, test_accuracy = model.evaluate(test_dataset, verbose = 0)\n",
        "                print(f\"Test accuracy: {test_accuracy * 100:.2f}%, Test loss: {test_loss:.4f}\")\n",
        "\n",
        "                # Updating the results DataFrame\n",
        "                results_df = results_df.append({\n",
        "                    'Neurons': neurons,\n",
        "                    'Activation': activation,\n",
        "                    'Dropout': dropout_rate,\n",
        "                    'Frozen Layers': frozen_layers,\n",
        "                    'Test Accuracy': test_accuracy,\n",
        "                    'Test Loss': test_loss\n",
        "                }, ignore_index=True)\n",
        "\n",
        "                # Saving the best model\n",
        "                if test_accuracy > best_accuracy:\n",
        "                    best_accuracy = test_accuracy\n",
        "                    best_model_details = {\n",
        "                        'Neurons': neurons,\n",
        "                        'Activation': activation,\n",
        "                        'Dropout': dropout_rate,\n",
        "                        'Frozen Layers': frozen_layers,\n",
        "                        'Test Set Accuracy': f\"{test_accuracy * 100:.2f}%\"\n",
        "                    }\n",
        "                    model.save(f'{base_dir}/Best_DenseNet121_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3ScgAthHmogw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25a2d0f-9b52-456c-ce6f-5246a3f49d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Neurons Activation Dropout Frozen Layers  Test Accuracy  Test Loss\n",
            "0      256       relu       0           427          0.968   0.120673\n",
            "1      256       relu       0           425          0.944   0.220135\n",
            "2      256       relu       0           422          0.952   0.465289\n",
            "3      256       relu     0.3           427          0.944   0.139316\n",
            "4      256       relu     0.3           425          0.952   0.133540\n",
            "5      256       relu     0.3           422          0.936   0.253680\n",
            "6      256       relu     0.5           427          0.920   0.164451\n",
            "7      256       relu     0.5           425          0.904   0.172330\n",
            "8      256       relu     0.5           422          0.936   0.162019\n",
            "9      512       relu       0           427          0.952   0.285922\n",
            "10     512       relu       0           425          0.968   0.145568\n",
            "11     512       relu       0           422          0.912   0.368659\n",
            "12     512       relu     0.3           427          0.960   0.101546\n",
            "13     512       relu     0.3           425          0.968   0.168398\n",
            "14     512       relu     0.3           422          0.920   0.174795\n",
            "15     512       relu     0.5           427          0.912   0.257466\n",
            "16     512       relu     0.5           425          0.912   0.188604\n",
            "17     512       relu     0.5           422          0.928   0.208436\n"
          ]
        }
      ],
      "source": [
        "# Displaying all results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xFs9-MZbms8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907a9e5e-b8b1-4697-c5f1-5831f7aafc6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model details: {'Neurons': 256, 'Activation': 'relu', 'Dropout': 0, 'Frozen Layers': 427, 'Test Set Accuracy': '96.80%'}\n"
          ]
        }
      ],
      "source": [
        "# Displaying the best model's details\n",
        "print(\"Best model details:\", best_model_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fduRWJt26J"
      },
      "source": [
        "# **Model Ensembles:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qj80uIVQt8hg"
      },
      "outputs": [],
      "source": [
        "# Loading the label encodings from a previously made joblib file\n",
        "\n",
        "label_encoder = joblib.load(f'{base_dir}/label_encoder.joblib')\n",
        "\n",
        "# Loading the individual models\n",
        "\n",
        "model_vgg19 = load_model(f'{base_dir}/Best_VGG19_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J2TgsuZp-6ho"
      },
      "outputs": [],
      "source": [
        "model_inceptionv3 = load_model(f'{base_dir}/Best_InceptionV3_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xq0oC3U4-8_c"
      },
      "outputs": [],
      "source": [
        "model_resnet50 = load_model(f'{base_dir}/Best_ResNet50_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zVLo-pxR--q9"
      },
      "outputs": [],
      "source": [
        "model_densenet121 = load_model(f'{base_dir}/Best_DenseNet121_Visual_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KS11pnr8uL9g"
      },
      "outputs": [],
      "source": [
        "# Functions to preprocess the images to meet the requirements of the pertinent pre-trained model\n",
        "def preprocess_image_vgg19(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True)\n",
        "  img = preprocess_input_vgg(img)\n",
        "  return img, label\n",
        "\n",
        "def preprocess_image_inceptionv3(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 299, 299, antialias=True)\n",
        "  img = preprocess_input_inception(img)\n",
        "  return img, label\n",
        "\n",
        "def preprocess_image_resnet50(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True)\n",
        "  img = preprocess_input_resnet(img)\n",
        "  return img, label\n",
        "\n",
        "def preprocess_image_densenet121(file_path, label):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224, antialias=True)\n",
        "  img = preprocess_input_densenet(img)\n",
        "  return img, label\n",
        "\n",
        "# Function to prepare the test dataset to be compatible with TensorFlow\n",
        "def prepare_dataset(df, image_dir, preprocessing_function, batch_size=32, cache=True, shuffle=False):\n",
        "    image_paths = df['Id'].apply(lambda x: f\"{image_dir}/{x}\").values\n",
        "    labels = label_encoder.transform(df['Class'].values)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "    dataset = dataset.map(preprocessing_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eloGI6irvewg"
      },
      "outputs": [],
      "source": [
        "# Preparing the test dataset to be compatible with each of the models using the above functions\n",
        "test_dataset_vgg19 = prepare_dataset(test_df, test_image_dir, preprocess_image_vgg19, batch_size=batch_size, cache=True)\n",
        "test_dataset_inceptionv3 = prepare_dataset(test_df, test_image_dir, preprocess_image_inceptionv3, batch_size=batch_size, cache=True)\n",
        "test_dataset_resnet50 = prepare_dataset(test_df, test_image_dir, preprocess_image_resnet50, batch_size=batch_size, cache=True)\n",
        "test_dataset_densenet121 = prepare_dataset(test_df, test_image_dir, preprocess_image_densenet121, batch_size=batch_size, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8PbcMshcvhx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440930eb-6d31-4c65-81f7-2ca76946e054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 3s 54ms/step\n",
            "32/32 [==============================] - 5s 80ms/step\n",
            "32/32 [==============================] - 3s 48ms/step\n",
            "32/32 [==============================] - 4s 47ms/step\n"
          ]
        }
      ],
      "source": [
        "# Making class probability predictions for each model\n",
        "predictions_vgg19 = model_vgg19.predict(test_dataset_vgg19)\n",
        "predictions_inceptionv3 = model_inceptionv3.predict(test_dataset_inceptionv3)\n",
        "predictions_resnet50 = model_resnet50.predict(test_dataset_resnet50)\n",
        "predictions_densenet121 = model_densenet121.predict(test_dataset_densenet121)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aNBv6dD1vxNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81404867-24f6-43f2-8548-1eb8436573b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 5ms/step\n",
            "32/32 [==============================] - 0s 9ms/step\n",
            "32/32 [==============================] - 0s 6ms/step\n",
            "32/32 [==============================] - 0s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "# Making class predictions for each model\n",
        "class_predictions_vgg19 = np.argmax(model_vgg19.predict(test_dataset_vgg19), axis=1)\n",
        "class_predictions_inceptionv3 = np.argmax(model_inceptionv3.predict(test_dataset_inceptionv3), axis=1)\n",
        "class_predictions_resnet50 = np.argmax(model_resnet50.predict(test_dataset_resnet50), axis=1)\n",
        "class_predictions_densenet121 = np.argmax(model_densenet121.predict(test_dataset_densenet121), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6HoePjwDvkUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4adc41-85f6-4296-94ea-b2c1bb08d37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Model (Soft Voting) Accuracy: 0.976\n"
          ]
        }
      ],
      "source": [
        "# Using soft-voting to make predictions\n",
        "ensemble_predictions = (predictions_vgg19 + predictions_inceptionv3 + predictions_resnet50 + predictions_densenet121) / 4\n",
        "\n",
        "true_labels = test_df['Class'].values\n",
        "true_labels_encoded = label_encoder.transform(true_labels)\n",
        "predicted_classes = np.argmax(ensemble_predictions, axis=1)\n",
        "\n",
        "ensemble_model_acc = accuracy_score(true_labels_encoded, predicted_classes)\n",
        "print(f'Ensemble Model (Soft Voting) Accuracy: {ensemble_model_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "d3_uqDEDvqOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022721eb-ac99-4189-81d8-ddc48e9c7ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Model (Majority Voting) Accuracy: 0.976\n"
          ]
        }
      ],
      "source": [
        "# Using majority voting to make predictions\n",
        "stacked_predictions = np.column_stack((class_predictions_vgg19, class_predictions_inceptionv3, class_predictions_resnet50, class_predictions_densenet121))\n",
        "ensemble_predictions = mode(stacked_predictions, axis=1)[0].flatten()\n",
        "\n",
        "true_labels = test_df['Class'].values\n",
        "true_labels_encoded = label_encoder.transform(true_labels)\n",
        "\n",
        "ensemble_model_acc = accuracy_score(true_labels_encoded, ensemble_predictions)\n",
        "print(f'Ensemble Model (Majority Voting) Accuracy: {ensemble_model_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XiR93SmNNON"
      },
      "source": [
        "# **The ensemble model accuracy of 97.6% is tied with the individual ResNet50 model. However, it is still smaller than the highest hybrid model accuracy.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}